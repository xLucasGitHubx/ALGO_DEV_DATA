{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application météo — Stations de Toulouse Métropole\n",
    "\n",
    "Ce notebook contient l'application météo pour **la ville de Toulouse et ses différentes stations météo**.\n",
    "\n",
    "- Exploration du catalogue `data.toulouse-metropole.fr`.\n",
    "- Détection uniquement des datasets de type `station-meteo-...` (réseau de capteurs météo).\n",
    "- Ingestion d'un petit nombre de mesures par station.\n",
    "- Affichage global des dernières observations.\n",
    "- **Carrousel** qui parcourt les stations une par une toutes les 5 secondes (liste chaînée).\n",
    "\n",
    "La configuration est centralisée dans le dictionnaire Python `APP_CONFIG`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import time\n",
    "import unicodedata\n",
    "from collections.abc import Iterator\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# ==============================\n",
    "# Constantes\n",
    "# ==============================\n",
    "\n",
    "DEFAULT_BASE_URL = os.environ.get(\n",
    "    \"ODS_BASE_URL\",\n",
    "    \"https://data.toulouse-metropole.fr/api/explore/v2.1\",\n",
    ")\n",
    "\n",
    "HTTP_TIMEOUT = 20  # secondes\n",
    "CATALOG_PAGE_SIZE = 100  # max autorisé sans group_by\n",
    "CATALOG_HARD_LIMIT = 10_000  # sécurité\n",
    "RECORDS_PAGE_SIZE = 100  # max autorisé pour records\n",
    "PRINT_WIDTH = 110\n",
    "\n",
    "JSONLike = dict[str, object]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Configuration applicative\n",
    "# ==============================\n",
    "\n",
    "APP_CONFIG: dict[str, object] = {\n",
    "    # URL de base de l'API Opendatasoft (Toulouse Métropole)\n",
    "    \"base_url\": DEFAULT_BASE_URL,\n",
    "    # Paramètres liés au catalogue\n",
    "    \"catalog\": {\n",
    "        \"hard_limit\": CATALOG_HARD_LIMIT,  # nombre max de datasets parcourus\n",
    "    },\n",
    "    # Paramètres d'ingestion des données météo\n",
    "    \"ingestion\": {\n",
    "        \"max_rows_per_station\": 3,   # nombre de mesures ingérées par station\n",
    "        \"max_stations\": None,        # None => toutes les stations détectées\n",
    "    },\n",
    "    # Paramètres d'affichage (console)\n",
    "    \"ui\": {\n",
    "        \"enable_carousel\": True,     # active le carrousel station par station\n",
    "        \"carousel_delay_sec\": 5,     # délai entre 2 stations en secondes\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Helpers simples\n",
    "# ==============================\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    \"\"\"Normalise texte : minuscule + suppression accents + trim.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if s is None else str(s)\n",
    "    s = s.strip().lower()\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) != \"Mn\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def _parse_datetime_any(x: object | None) -> datetime | None:\n",
    "    \"\"\"Tente de parser divers formats date/datetime retournés par ODS.\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, datetime):\n",
    "        return x\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Formats fréquents\n",
    "    candidates = [\n",
    "        \"%Y-%m-%dT%H:%M:%S%z\",\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f%z\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%d\",\n",
    "    ]\n",
    "    for fmt in candidates:\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    # Dernière chance : enlever le fuseau si présent\n",
    "    if s.endswith(\"Z\"):\n",
    "        try:\n",
    "            return datetime.strptime(s[:-1], \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.strptime(s[:-1], \"%Y-%m-%dT%H:%M:%S\")\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Domain models\n",
    "# ==============================\n",
    "\n",
    "@dataclass\n",
    "class Station:\n",
    "    id: str\n",
    "    name: str\n",
    "    dataset_id: str\n",
    "    meta: JSONLike = field(default_factory=dict)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WeatherRecord:\n",
    "    station_id: str\n",
    "    timestamp: datetime | None = None\n",
    "    temperature_c: float | None = None\n",
    "    humidity_pct: float | None = None\n",
    "    pressure_hpa: float | None = None\n",
    "    wind_speed_ms: float | None = None\n",
    "    wind_dir_deg: float | None = None\n",
    "    rain_mm: float | None = None\n",
    "    raw: JSONLike = field(default_factory=dict)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Repositories en mémoire\n",
    "# ==============================\n",
    "\n",
    "class WeatherRepositoryMemory:\n",
    "    def __init__(self) -> None:\n",
    "        self._stations: dict[str, Station] = {}\n",
    "        self._records: dict[str, list[WeatherRecord]] = {}\n",
    "\n",
    "    def upsert_station(self, st: Station) -> None:\n",
    "        self._stations[st.id] = st\n",
    "        self._records.setdefault(st.id, [])\n",
    "\n",
    "    def get_station(self, station_id: str) -> Station | None:\n",
    "        return self._stations.get(station_id)\n",
    "\n",
    "    def list_stations(self) -> list[Station]:\n",
    "        return list(self._stations.values())\n",
    "\n",
    "    def add_record(self, station_id: str, rec: WeatherRecord) -> None:\n",
    "        self._records.setdefault(station_id, []).append(rec)\n",
    "\n",
    "    def latest_records(self, station_id: str, n: int = 5) -> list[WeatherRecord]:\n",
    "        arr = self._records.get(station_id, [])\n",
    "        arr = sorted(arr, key=lambda r: r.timestamp or datetime.min, reverse=True)\n",
    "        return arr[:n]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Client ODS Explore v2.1\n",
    "# ==============================\n",
    "\n",
    "class ODSClient:\n",
    "    def __init__(self, base_url: str | None = None) -> None:\n",
    "        base = base_url or str(APP_CONFIG.get(\"base_url\") or DEFAULT_BASE_URL)\n",
    "        self.base_url = base.rstrip(\"/\")\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"Accept\": \"application/json; charset=utf-8\",\n",
    "            \"User-Agent\": \"POO-Meteo/1.2 (+python requests)\",\n",
    "        })\n",
    "\n",
    "    # --- HTTP core ---\n",
    "\n",
    "    def _request(self, method: str, path: str, **kwargs) -> JSONLike:\n",
    "        url = f\"{self.base_url}{path}\"\n",
    "        resp = self.session.request(method, url, timeout=HTTP_TIMEOUT, **kwargs)\n",
    "        resp.raise_for_status()\n",
    "        if resp.headers.get(\"Content-Type\", \"\").startswith(\"application/json\"):\n",
    "            return resp.json()\n",
    "        return {\"_raw\": resp.content}\n",
    "\n",
    "    # --- Catalog ---\n",
    "\n",
    "    def catalog_datasets_page(\n",
    "        self,\n",
    "        limit: int = CATALOG_PAGE_SIZE,\n",
    "        offset: int = 0,\n",
    "        include_links: bool = False,\n",
    "        include_app_metas: bool = False,\n",
    "    ) -> JSONLike:\n",
    "        params = {\n",
    "            \"limit\": max(1, min(limit, CATALOG_PAGE_SIZE)),\n",
    "            \"offset\": max(0, offset),\n",
    "            \"include_links\": str(include_links).lower(),\n",
    "            \"include_app_metas\": str(include_app_metas).lower(),\n",
    "        }\n",
    "        return self._request(\"GET\", \"/catalog/datasets\", params=params)\n",
    "\n",
    "    def catalog_datasets_iter(self, hard_limit: int | None = None) -> Iterator[JSONLike]:\n",
    "        \"\"\"Page sur l'ensemble du catalogue.\"\"\"\n",
    "        catalog_cfg = APP_CONFIG.get(\"catalog\") or {}\n",
    "        default_limit = catalog_cfg.get(\"hard_limit\", CATALOG_HARD_LIMIT)\n",
    "        effective_hard_limit = hard_limit or int(default_limit)\n",
    "\n",
    "        total_yielded = 0\n",
    "        offset = 0\n",
    "        while True:\n",
    "            page = self.catalog_datasets_page(limit=CATALOG_PAGE_SIZE, offset=offset)\n",
    "            results = page.get(\"results\", []) or []\n",
    "            if not results:\n",
    "                break\n",
    "            for ds in results:\n",
    "                yield ds\n",
    "                total_yielded += 1\n",
    "                if total_yielded >= effective_hard_limit:\n",
    "                    return\n",
    "            offset += len(results)\n",
    "            if offset >= (page.get(\"total_count\") or 0):\n",
    "                break\n",
    "\n",
    "    # --- Dataset info & records ---\n",
    "\n",
    "    def dataset_info(self, dataset_id: str) -> JSONLike:\n",
    "        path = f\"/catalog/datasets/{dataset_id}\"\n",
    "        return self._request(\"GET\", path)\n",
    "\n",
    "    def iter_records(\n",
    "        self,\n",
    "        dataset_id: str,\n",
    "        select: str | None = None,\n",
    "        where: str | None = None,\n",
    "        order_by: str | None = None,\n",
    "        limit: int = RECORDS_PAGE_SIZE,\n",
    "        max_rows: int | None = None,\n",
    "    ) -> Iterator[JSONLike]:\n",
    "        \"\"\"\n",
    "        Itère sur les records du dataset.\n",
    "        \"\"\"\n",
    "        params_base: dict[str, object] = {}\n",
    "        if select:\n",
    "            params_base[\"select\"] = select\n",
    "        if where:\n",
    "            params_base[\"where\"] = where\n",
    "        if order_by:\n",
    "            params_base[\"order_by\"] = order_by\n",
    "\n",
    "        yielded = 0\n",
    "        offset = 0\n",
    "        while True:\n",
    "            remaining = (max_rows - yielded) if max_rows is not None else RECORDS_PAGE_SIZE\n",
    "            page_limit = min(RECORDS_PAGE_SIZE, remaining) if max_rows is not None else RECORDS_PAGE_SIZE\n",
    "\n",
    "            params = dict(params_base)\n",
    "            params[\"limit\"] = page_limit\n",
    "            params[\"offset\"] = offset\n",
    "\n",
    "            res = self._request(\"GET\", f\"/catalog/datasets/{dataset_id}/records\", params=params)\n",
    "            results = res.get(\"results\", []) or []\n",
    "            if not results:\n",
    "                break\n",
    "            for row in results:\n",
    "                yield row\n",
    "                yielded += 1\n",
    "                if max_rows is not None and yielded >= max_rows:\n",
    "                    return\n",
    "            offset += len(results)\n",
    "            if len(results) < page_limit:\n",
    "                break\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Nettoyage / mapping champs\n",
    "# ==============================\n",
    "\n",
    "class BasicCleaner:\n",
    "    \"\"\"\n",
    "    Transforme une ligne brute ODS en WeatherRecord.\n",
    "    Détecte au mieux les synonymes de champs (température, humidité, etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    TEMP_KEYS = [\"temperature\", \"temp\", \"temp_c\", \"tair\", \"temperature_c\", \"t\", \"tc\"]\n",
    "    HUM_KEYS = [\"humidity\", \"humidite\", \"hum\", \"rh\", \"hr\", \"humidite_rel\", \"hum_rel\"]\n",
    "    P_KEYS = [\"pressure\", \"pression\", \"press_hpa\", \"pression_hpa\", \"p\", \"pa\", \"p_hpa\"]\n",
    "    WIND_S_KEYS = [\"wind_speed\", \"wind\", \"vitesse_vent\", \"ff\", \"ff10\", \"vent_ms\", \"vent_vitesse\"]\n",
    "    WIND_D_KEYS = [\"wind_dir\", \"wind_direction\", \"dd\", \"dir_vent\", \"direction_vent\"]\n",
    "    RAIN_KEYS = [\"rain\", \"pluie\", \"precipitation\", \"precipitations\", \"rr\", \"rr1\", \"rr24\"]\n",
    "\n",
    "    TS_PREF = [\"date_observation\", \"date_mesure\", \"date_heure\", \"date\", \"datetime\", \"timestamp\", \"heure\", \"time\"]\n",
    "\n",
    "    def _get_first(self, data: JSONLike, keys: list[str]) -> object | None:\n",
    "        keys_norm = [_norm(k) for k in data.keys()]\n",
    "        mapping = {kn: k for k, kn in zip(data.keys(), keys_norm)}\n",
    "        for kk in keys:\n",
    "            kkn = _norm(kk)\n",
    "            if kkn in mapping:\n",
    "                return data[mapping[kkn]]\n",
    "        for kk in keys:\n",
    "            kkn = _norm(kk)\n",
    "            for kn, orig in mapping.items():\n",
    "                if kkn in kn:\n",
    "                    return data[orig]\n",
    "        return None\n",
    "\n",
    "    def _to_float(self, x: object | None) -> float | None:\n",
    "        if x is None or x == \"\":\n",
    "            return None\n",
    "        try:\n",
    "            return float(str(x).replace(\",\", \".\"))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def clean(self, raw: JSONLike, station_id: str) -> WeatherRecord:\n",
    "        ts_raw = self._get_first(raw, self.TS_PREF)\n",
    "        ts = _parse_datetime_any(ts_raw)\n",
    "\n",
    "        t = self._to_float(self._get_first(raw, self.TEMP_KEYS))\n",
    "        hum = self._to_float(self._get_first(raw, self.HUM_KEYS))\n",
    "        p = self._to_float(self._get_first(raw, self.P_KEYS))\n",
    "        ws = self._to_float(self._get_first(raw, self.WIND_S_KEYS))\n",
    "        wd = self._to_float(self._get_first(raw, self.WIND_D_KEYS))\n",
    "        rr = self._to_float(self._get_first(raw, self.RAIN_KEYS))\n",
    "\n",
    "        return WeatherRecord(\n",
    "            station_id=station_id,\n",
    "            timestamp=ts,\n",
    "            temperature_c=t,\n",
    "            humidity_pct=hum,\n",
    "            pressure_hpa=p,\n",
    "            wind_speed_ms=ws,\n",
    "            wind_dir_deg=wd,\n",
    "            rain_mm=rr,\n",
    "            raw=raw,\n",
    "        )\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Catalogue de stations (Toulouse uniquement)\n",
    "# ==============================\n",
    "\n",
    "class StationCatalogSimple:\n",
    "    \"\"\"\n",
    "    Explore le catalogue *de Toulouse Métropole* et identifie les datasets\n",
    "    correspondant aux stations météo physiques, c'est-à-dire les datasets\n",
    "    dont l'identifiant contient 'station-meteo-'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Groupes de tokens météo pour sécuriser encore un peu la détection\n",
    "    TEMP_TOKENS = {\n",
    "        \"temperature\", \"temperatures\", \"température\", \"tair\", \"temp_c\", \"tc\",\n",
    "        \"temp\", \"temperature_c\",\n",
    "    }\n",
    "    HUM_TOKENS = {\n",
    "        \"humidity\", \"humidite\", \"humidité\", \"rh\", \"hr\", \"humidite_rel\", \"hum_rel\",\n",
    "    }\n",
    "    PRESS_TOKENS = {\n",
    "        \"pression\", \"pressure\", \"press_hpa\", \"pression_hpa\", \"hpa\",\n",
    "    }\n",
    "    WIND_TOKENS = {\n",
    "        \"vent\", \"wind\", \"rafale\", \"rafales\", \"gust\", \"ff\", \"ff10\", \"dd\",\n",
    "        \"direction_vent\", \"vitesse_vent\", \"vent_ms\",\n",
    "    }\n",
    "    RAIN_TOKENS = {\n",
    "        \"rain\", \"pluie\", \"pluvio\", \"precipitation\", \"precipitations\", \"rr\",\n",
    "        \"rr1\", \"rr24\", \"rr24h\",\n",
    "    }\n",
    "\n",
    "    EXCLUDE_DATASET_IDS = {\n",
    "        \"previsions-meteo-france-metropole\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, ods: ODSClient, repo: WeatherRepositoryMemory) -> None:\n",
    "        self.ods = ods\n",
    "        self.repo = repo\n",
    "        self._weather: list[JSONLike] = []\n",
    "\n",
    "    def _is_weather_like(self, ds: JSONLike) -> bool:\n",
    "        dsid = ds.get(\"dataset_id\")\n",
    "        if not dsid:\n",
    "            return False\n",
    "\n",
    "        # 1) On ne garde que les datasets de type \"station-meteo-...\"\n",
    "        if \"station-meteo-\" not in dsid:\n",
    "            return False\n",
    "\n",
    "        if dsid in self.EXCLUDE_DATASET_IDS:\n",
    "            return False\n",
    "\n",
    "        fields = ds.get(\"fields\", []) or []\n",
    "\n",
    "        # Texte combiné name+label pour chaque champ\n",
    "        fields_text = \" \".join(\n",
    "            f\"{_norm(f.get('name') or '')} {_norm(f.get('label') or '')}\"\n",
    "            for f in fields\n",
    "        )\n",
    "\n",
    "        # Tokenisation simple\n",
    "        buf = []\n",
    "        for ch in fields_text:\n",
    "            if ch.isalnum():\n",
    "                buf.append(ch)\n",
    "            else:\n",
    "                buf.append(\" \")\n",
    "        tokens = {tok for tok in \"\".join(buf).split() if tok}\n",
    "\n",
    "        groups = 0\n",
    "        if tokens & self.TEMP_TOKENS:\n",
    "            groups += 1\n",
    "        if tokens & self.HUM_TOKENS:\n",
    "            groups += 1\n",
    "        if tokens & self.PRESS_TOKENS:\n",
    "            groups += 1\n",
    "        if tokens & self.WIND_TOKENS:\n",
    "            groups += 1\n",
    "        if tokens & self.RAIN_TOKENS:\n",
    "            groups += 1\n",
    "\n",
    "        if groups == 0:\n",
    "            return False\n",
    "\n",
    "        # Champ géographique souvent présent sur les stations\n",
    "        has_geo = any((f.get(\"type\") == \"geo_point_2d\") for f in fields)\n",
    "\n",
    "        # Au moins 2 groupes de mesures, ou 1 groupe + géolocalisation\n",
    "        return (groups >= 2) or (groups >= 1 and has_geo)\n",
    "\n",
    "    def load(self) -> None:\n",
    "        print(\"Chargement du catalogue (stations météo Toulouse)…\")\n",
    "        items: list[JSONLike] = []\n",
    "        for ds in self.ods.catalog_datasets_iter():\n",
    "            if self._is_weather_like(ds):\n",
    "                items.append(ds)\n",
    "        self._weather = items\n",
    "\n",
    "        # Création de \"stations\" à partir des datasets retenus\n",
    "        for ds in self._weather:\n",
    "            metas = (ds.get(\"metas\", {}) or {}).get(\"default\", {}) or {}\n",
    "            title = metas.get(\"title\") or ds.get(\"dataset_id\")\n",
    "            dsid = ds.get(\"dataset_id\")\n",
    "            if not dsid:\n",
    "                continue\n",
    "            st = Station(id=dsid, name=str(title), dataset_id=str(dsid), meta=metas)\n",
    "            self.repo.upsert_station(st)\n",
    "\n",
    "    def datasets(self) -> list[JSONLike]:\n",
    "        return list(self._weather)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Services\n",
    "# ==============================\n",
    "\n",
    "class WeatherIngestionService:\n",
    "    def __init__(self, ods: ODSClient, repo: WeatherRepositoryMemory, cleaner: BasicCleaner) -> None:\n",
    "        self.ods = ods\n",
    "        self.repo = repo\n",
    "        self.cleaner = cleaner\n",
    "\n",
    "    def _find_first_date_field(self, dataset_id: str) -> str | None:\n",
    "        info = self.ods.dataset_info(dataset_id)\n",
    "        fields = (info.get(\"fields\") or [])\n",
    "        preferred = [\"date_observation\", \"date_mesure\", \"date\", \"datetime\", \"timestamp\", \"time\", \"heure\"]\n",
    "        by_type = [f.get(\"name\") for f in fields if f.get(\"type\") in (\"date\", \"datetime\")]\n",
    "        for p in preferred:\n",
    "            if any(_norm(f.get(\"name\") or \"\") == _norm(p) for f in fields):\n",
    "                return p\n",
    "        return by_type[0] if by_type else None\n",
    "\n",
    "    def ingest_latest(self, station: Station, max_rows: int = 5) -> int:\n",
    "        dataset_id = station.dataset_id\n",
    "        if not dataset_id:\n",
    "            return 0\n",
    "\n",
    "        order_field = None\n",
    "        try:\n",
    "            order_field = self._find_first_date_field(dataset_id)\n",
    "        except requests.HTTPError:\n",
    "            order_field = None\n",
    "\n",
    "        order_by = f\"{order_field} desc\" if order_field else None\n",
    "        count = 0\n",
    "        try:\n",
    "            for row in self.ods.iter_records(dataset_id=dataset_id, order_by=order_by, max_rows=max_rows):\n",
    "                rec = self.cleaner.clean(row, station_id=station.id)\n",
    "                self.repo.add_record(station.id, rec)\n",
    "                count += 1\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"Échec lecture records ({dataset_id}) : {e}\")\n",
    "        return count\n",
    "\n",
    "    def ingest_all_latest(self, max_rows_per_station: int = 3, max_stations: int | None = None) -> int:\n",
    "        stations = self.repo.list_stations()\n",
    "        if max_stations is not None:\n",
    "            stations = stations[:max_stations]\n",
    "\n",
    "        total = 0\n",
    "        for st in stations:\n",
    "            n = self.ingest_latest(st, max_rows=max_rows_per_station)\n",
    "            total += n\n",
    "        return total\n",
    "\n",
    "\n",
    "class WeatherQueryService:\n",
    "    def __init__(self, repo: WeatherRepositoryMemory) -> None:\n",
    "        self.repo = repo\n",
    "\n",
    "    def latest_for_station(self, station_id: str, n: int = 1) -> list[WeatherRecord]:\n",
    "        return self.repo.latest_records(station_id, n=n)\n",
    "\n",
    "\n",
    "class ForecastService:\n",
    "    \"\"\"Prévision jouet = moyenne des N dernières températures observées.\"\"\"\n",
    "\n",
    "    def __init__(self, repo: WeatherRepositoryMemory) -> None:\n",
    "        self.repo = repo\n",
    "\n",
    "    def forecast_station_temp(self, station_id: str, last_n: int = 3) -> float | None:\n",
    "        rows = self.repo.latest_records(station_id, n=last_n)\n",
    "        temps = [r.temperature_c for r in rows if r.temperature_c is not None]\n",
    "        if not temps:\n",
    "            return None\n",
    "        return sum(temps) / len(temps)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Rendu console\n",
    "# ==============================\n",
    "\n",
    "class SimpleRenderer:\n",
    "    @staticmethod\n",
    "    def print_datasets(datasets: list[JSONLike], max_rows: int = 20) -> None:\n",
    "        print(\"\\n=== Stations météo détectées dans le catalogue (Toulouse Métropole) ===\")\n",
    "        if not datasets:\n",
    "            print(\"(aucune station météo détectée)\")\n",
    "            return\n",
    "\n",
    "        print(f\"(affichage des {min(max_rows, len(datasets))} premiers sur {len(datasets)})\\n\")\n",
    "        print(f\"{'dataset_id':<60} {'records':>7}  title\")\n",
    "        print(\"-\" * PRINT_WIDTH)\n",
    "        for ds in datasets[:max_rows]:\n",
    "            dsid = ds.get(\"dataset_id\", \"\") or \"\"\n",
    "            metas = (ds.get(\"metas\", {}) or {}).get(\"default\", {}) or {}\n",
    "            title = metas.get(\"title\") or dsid\n",
    "            records = metas.get(\"records_count\")\n",
    "            rec_s = f\"{records}\" if records is not None else \"-\"\n",
    "            print(f\"{dsid:<60} {rec_s:>7}  {str(title)[:PRINT_WIDTH-80]}\")\n",
    "        print(\"-\" * PRINT_WIDTH)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_latest(repo: WeatherRepositoryMemory) -> None:\n",
    "        print(\"\\n=== Observations récentes par station (Toulouse Métropole) ===\")\n",
    "        for st in repo.list_stations():\n",
    "            latest = repo.latest_records(st.id, n=1)\n",
    "            if latest:\n",
    "                r = latest[0]\n",
    "                ts = r.timestamp.isoformat(sep=\" \", timespec=\"seconds\") if r.timestamp else \"-\"\n",
    "                t = f\"{r.temperature_c:.1f}°C\" if r.temperature_c is not None else \"?\"\n",
    "                hum = f\"{r.humidity_pct:.0f}%\" if r.humidity_pct is not None else \"?\"\n",
    "                ws = f\"{r.wind_speed_ms:.1f} m/s\" if r.wind_speed_ms is not None else \"?\"\n",
    "                rr = f\"{r.rain_mm:.1f} mm\" if r.rain_mm is not None else \"0\"\n",
    "                print(f\"[{st.dataset_id}] {st.name}  •  dernière obs: {ts}  •  T={t}  H={hum}  Vent={ws}  Pluie={rr}\")\n",
    "            else:\n",
    "                print(f\"[{st.dataset_id}] {st.name}  •  dernière obs: -\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Carrousel station par station\n",
    "# ==============================\n",
    "\n",
    "class StationCarouselRenderer:\n",
    "    \"\"\"\n",
    "    Carrousel console : affiche les stations une par une, en boucle,\n",
    "    avec un délai fixe entre chaque station.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repo: WeatherRepositoryMemory, forecast: ForecastService, delay_seconds: int = 5) -> None:\n",
    "        self.repo = repo\n",
    "        self.forecast = forecast\n",
    "        self.delay_seconds = delay_seconds\n",
    "\n",
    "    def _format_record_line(self, st: Station) -> str:\n",
    "        latest = self.repo.latest_records(st.id, n=1)\n",
    "        if not latest:\n",
    "            return f\"[{st.dataset_id}] {st.name}\\n  • Aucune observation récente disponible.\"\n",
    "        r = latest[0]\n",
    "        ts = r.timestamp.isoformat(sep=\" \", timespec=\"seconds\") if r.timestamp else \"-\"\n",
    "        t = f\"{r.temperature_c:.1f}°C\" if r.temperature_c is not None else \"?\"\n",
    "        hum = f\"{r.humidity_pct:.0f}%\" if r.humidity_pct is not None else \"?\"\n",
    "        ws = f\"{r.wind_speed_ms:.1f} m/s\" if r.wind_speed_ms is not None else \"?\"\n",
    "        rr = f\"{r.rain_mm:.1f} mm\" if r.rain_mm is not None else \"0\"\n",
    "        return (\n",
    "            f\"[{st.dataset_id}] {st.name}\\n\"\n",
    "            f\"  • Dernière obs: {ts}\\n\"\n",
    "            f\"  • T={t}  H={hum}  Vent={ws}  Pluie={rr}\"\n",
    "        )\n",
    "\n",
    "    def _format_forecast_line(self, st: Station) -> str:\n",
    "        yhat = self.forecast.forecast_station_temp(st.id)\n",
    "        if yhat is None:\n",
    "            return \"  • Prévision jouet: indisponible (pas assez de données)\"\n",
    "        return f\"  • Prévision jouet: temp ≈ {yhat:.2f} °C\"\n",
    "\n",
    "    def run(self) -> None:\n",
    "        stations = self.repo.list_stations()\n",
    "        if not stations:\n",
    "            print(\"\\nAucune station météo détectée, rien à afficher en mode carrousel.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n=== Parcours station par station (Toulouse) ===\")\n",
    "        print(\"Utilisez Ctrl+C pour arrêter.\\n\")\n",
    "        idx = 0\n",
    "        n = len(stations)\n",
    "        try:\n",
    "            while True:\n",
    "                st = stations[idx]\n",
    "                print(\"=\" * PRINT_WIDTH)\n",
    "                print(self._format_record_line(st))\n",
    "                print(self._format_forecast_line(st))\n",
    "                print(f\"\\n→ Passage à la station suivante dans {self.delay_seconds} secondes…\")\n",
    "                time.sleep(self.delay_seconds)\n",
    "                idx = (idx + 1) % n\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nArrêt du carrousel demandé par l'utilisateur.\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Main\n",
    "# ==============================\n",
    "\n",
    "def main() -> None:\n",
    "    ods = ODSClient()\n",
    "    repo = WeatherRepositoryMemory()\n",
    "    catalog = StationCatalogSimple(ods, repo)\n",
    "\n",
    "    # Option : forcer un dataset précis via variable d'environnement\n",
    "    force_id = os.environ.get(\"ODS_DATASET_ID\")\n",
    "    if force_id:\n",
    "        print(f\"Ingestion forcée du dataset (station unique) : {force_id}\")\n",
    "        st = Station(id=force_id, name=force_id, dataset_id=force_id)\n",
    "        repo.upsert_station(st)\n",
    "        ing = WeatherIngestionService(ods, repo, BasicCleaner())\n",
    "        ing.ingest_latest(st, max_rows=10)\n",
    "        SimpleRenderer.print_latest(repo)\n",
    "\n",
    "        fc = ForecastService(repo)\n",
    "        carousel = StationCarouselRenderer(repo, fc, delay_seconds=int(APP_CONFIG[\"ui\"][\"carousel_delay_sec\"]))\n",
    "        carousel.run()\n",
    "        return\n",
    "\n",
    "    # Parcours du catalogue + détection stations météo (Toulouse)\n",
    "    try:\n",
    "        catalog.load()\n",
    "    except requests.HTTPError as e:\n",
    "        print(\"Erreur en chargeant le catalogue:\", e)\n",
    "        raise\n",
    "\n",
    "    ds_candidates = catalog.datasets()\n",
    "    SimpleRenderer.print_datasets(ds_candidates, max_rows=20)\n",
    "\n",
    "    # Ingestion d'un petit échantillon pour toutes les stations détectées\n",
    "    cleaner = BasicCleaner()\n",
    "    ing = WeatherIngestionService(ods, repo, cleaner)\n",
    "\n",
    "    ingestion_cfg = APP_CONFIG.get(\"ingestion\") or {}\n",
    "    max_rows_per_station = int(ingestion_cfg.get(\"max_rows_per_station\", 3))\n",
    "    max_stations_value = ingestion_cfg.get(\"max_stations\")\n",
    "    max_stations = int(max_stations_value) if isinstance(max_stations_value, int) else None\n",
    "\n",
    "    total_rows = ing.ingest_all_latest(\n",
    "        max_rows_per_station=max_rows_per_station,\n",
    "        max_stations=max_stations,\n",
    "    )\n",
    "    print(f\"\\nIngestion terminée ({total_rows} lignes au total).\")\n",
    "\n",
    "    # Rendu des dernières mesures\n",
    "    SimpleRenderer.print_latest(repo)\n",
    "\n",
    "    # Prévision jouet sur quelques stations\n",
    "    fc = ForecastService(repo)\n",
    "    for st in repo.list_stations()[:3]:\n",
    "        yhat = fc.forecast_station_temp(st.id)\n",
    "        if yhat is not None:\n",
    "            print(f\"Prévision jouet pour {st.name} → temp ≈ {yhat:.2f} °C\")\n",
    "\n",
    "    # Carrousel station par station (liste chaînée)\n",
    "    ui_cfg = APP_CONFIG.get(\"ui\") or {}\n",
    "    if ui_cfg.get(\"enable_carousel\", True):\n",
    "        delay = int(ui_cfg.get(\"carousel_delay_sec\", 5))\n",
    "        carousel = StationCarouselRenderer(repo, fc, delay_seconds=delay)\n",
    "        carousel.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du catalogue (stations météo Toulouse)…\n",
      "\n",
      "=== Stations météo détectées dans le catalogue (Toulouse Métropole) ===\n",
      "(affichage des 20 premiers sur 93)\n",
      "\n",
      "dataset_id                                                   records  title\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "08-station-meteo-toulouse-basso-cambo-archive-2019             18792  08 Station météo Toulouse Bass\n",
      "01-station-meteo-toulouse-meteopole-archive-2019               22587  01 Station météo Toulouse Mété\n",
      "10-station-meteo-castelginest-ecole-archive-2019               20394  10 Station météo Castelginest \n",
      "08-station-meteo-toulouse-basso-cambo-archive-2021             28063  08 Station météo Toulouse Bass\n",
      "08-station-meteo-toulouse-basso-cambo-archive-2020             34552  08 Station météo Toulouse Bass\n",
      "18-station-meteo-brax-ecole-archive-2020                       18388  18 Station météo Brax école - \n",
      "13-station-meteo-toulouse-pech-david-archive-2020               1231  13 Station météo Toulouse Pech\n",
      "18-station-meteo-brax-ecole-archive-2021                       34007  18 Station météo Brax école - \n",
      "12-station-meteo-toulouse-montaudran-archive-2019              18126  12 Station météo Toulouse Mont\n",
      "22-station-meteo-colomiers-za-perget-archive-2022              33019  22 Station météo Colomiers ZA \n",
      "18-station-meteo-brax-ecole-archive-2022                       30769  18 Station météo Brax école - \n",
      "45-station-meteo-toulouse-st-exupery                           87592  45 Station météo Toulouse St E\n",
      "48-station-meteo-toulouse-la-machine-af                        86269  48 Station météo Toulouse la M\n",
      "04-station-meteo-toulouse-ile-empalot                         156854  04 Station météo Toulouse Ile \n",
      "11-station-meteo-toulouse-soupetard-archive-2020               15390  11 Station météo Toulouse Soup\n",
      "17-station-meteo-fenouillet-foyer-archive-2020                 18388  17 Station météo Fenouillet fo\n",
      "37-station-meteo-toulouse-universite-paul-sabatier            171978  37 Station météo Toulouse univ\n",
      "41-station-meteo-toulouse-avenue-de-casselardit                73115  41 Station météo Toulouse Aven\n",
      "10-station-meteo-castelginest-ecole                           107006  10 Station météo Castelginest \n",
      "09-station-meteo-toulouse-la-salade-archive-2020                 357  09 Station météo Toulouse La S\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lancer l'application depuis le notebook\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrompu par l'utilisateur.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
